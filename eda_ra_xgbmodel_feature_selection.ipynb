{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T00:57:24.361365Z",
     "start_time": "2023-10-06T00:57:24.119125Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 500K dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        RECORD_ID ADD_TYPE AFAMPROFLS   AGE        AI_COUNTY_NAME AIRCOND  \\\n0          403390        S             21.0  Fairbanks North Star           \n1           62285        H              NaN             Anchorage           \n2          331355                      91.0       Kenai Peninsula           \n3          206320        H             65.0             Anchorage           \n4          188078        S             76.0                Juneau           \n...           ...      ...        ...   ...                   ...     ...   \n499995     349635        H             20.0                  BIBB           \n499996     420654        S             50.0                COWETA       A   \n499997     131262        S             19.0              ROCKDALE           \n499998     315673        H             21.0                BARROW           \n499999     467477        S             19.0               CHATHAM           \n\n       APP_CHILD APP_MENBIG APP_TODDLR APP_WOMEN  ... VTR_PRI16 VTR_PRI17  \\\n0                                                 ...                       \n1                                                 ...                       \n2                                                 ...                       \n3                                                 ...                       \n4                                                 ...         Y             \n...          ...        ...        ...       ...  ...       ...       ...   \n499995                                            ...                       \n499996                                            ...                       \n499997                                            ...                       \n499998                                            ...                       \n499999                                            ...                       \n\n       VTR_PRI18 VTR_PRI19 VTR_PRI20 VTR_PRI21 VTR_PRI22 WORKWOMAN YEARBUILT  \\\n0                                                                        NaN   \n1                                                                        NaN   \n2                                                                        NaN   \n3                                                      Y                       \n4              Y                                       Y         Y      1985   \n...          ...       ...       ...       ...       ...       ...       ...   \n499995                                                                   NaN   \n499996                                                                  2003   \n499997                                                                         \n499998                                                                   NaN   \n499999                                                                   NaN   \n\n          ZIP  \n0       99705  \n1       99506  \n2       99603  \n3       99567  \n4       99801  \n...       ...  \n499995  31204  \n499996  30263  \n499997  30013  \n499998  30680  \n499999  31407  \n\n[500000 rows x 298 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RECORD_ID</th>\n      <th>ADD_TYPE</th>\n      <th>AFAMPROFLS</th>\n      <th>AGE</th>\n      <th>AI_COUNTY_NAME</th>\n      <th>AIRCOND</th>\n      <th>APP_CHILD</th>\n      <th>APP_MENBIG</th>\n      <th>APP_TODDLR</th>\n      <th>APP_WOMEN</th>\n      <th>...</th>\n      <th>VTR_PRI16</th>\n      <th>VTR_PRI17</th>\n      <th>VTR_PRI18</th>\n      <th>VTR_PRI19</th>\n      <th>VTR_PRI20</th>\n      <th>VTR_PRI21</th>\n      <th>VTR_PRI22</th>\n      <th>WORKWOMAN</th>\n      <th>YEARBUILT</th>\n      <th>ZIP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>403390</td>\n      <td>S</td>\n      <td></td>\n      <td>21.0</td>\n      <td>Fairbanks North Star</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>NaN</td>\n      <td>99705</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62285</td>\n      <td>H</td>\n      <td></td>\n      <td>NaN</td>\n      <td>Anchorage</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>NaN</td>\n      <td>99506</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>331355</td>\n      <td></td>\n      <td></td>\n      <td>91.0</td>\n      <td>Kenai Peninsula</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>NaN</td>\n      <td>99603</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>206320</td>\n      <td>H</td>\n      <td></td>\n      <td>65.0</td>\n      <td>Anchorage</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>Y</td>\n      <td></td>\n      <td></td>\n      <td>99567</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>188078</td>\n      <td>S</td>\n      <td></td>\n      <td>76.0</td>\n      <td>Juneau</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td>Y</td>\n      <td></td>\n      <td>Y</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>1985</td>\n      <td>99801</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499995</th>\n      <td>349635</td>\n      <td>H</td>\n      <td></td>\n      <td>20.0</td>\n      <td>BIBB</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>NaN</td>\n      <td>31204</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>420654</td>\n      <td>S</td>\n      <td></td>\n      <td>50.0</td>\n      <td>COWETA</td>\n      <td>A</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>2003</td>\n      <td>30263</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>131262</td>\n      <td>S</td>\n      <td></td>\n      <td>19.0</td>\n      <td>ROCKDALE</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>30013</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>315673</td>\n      <td>H</td>\n      <td></td>\n      <td>21.0</td>\n      <td>BARROW</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>NaN</td>\n      <td>30680</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>467477</td>\n      <td>S</td>\n      <td></td>\n      <td>19.0</td>\n      <td>CHATHAM</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>NaN</td>\n      <td>31407</td>\n    </tr>\n  </tbody>\n</table>\n<p>500000 rows × 298 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_500 = pd.read_csv(\"/Users/nirugidla/Documents/GitHub/milestone2_MADS/data_500k.csv\", low_memory=False)\n",
    "data_500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T00:58:16.622214Z",
     "start_time": "2023-10-06T00:58:00.173566Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "        RECORD_ID ADD_TYPE AFAMPROFLS   AGE  AI_COUNTY_NAME  AIRCOND  \\\n84399      496231        S    Unknown  25.0         FLAGLER        A   \n484854     102544  Unknown    Unknown  62.0          TALBOT  Unknown   \n226471     373375        H    Unknown  55.0           SCOTT  Unknown   \n166786     390809        S    Unknown  61.0        SEDGWICK  Unknown   \n371588     204466        S    Unknown  23.0         NEWPORT  Unknown   \n...           ...      ...        ...   ...             ...      ...   \n160451     488765        S    Unknown  39.0        HAMILTON        A   \n440522     487245        S    Unknown  51.0  PRINCE WILLIAM  Unknown   \n386269     389513        S    Unknown  37.0           MEIGS  Unknown   \n258849     127079        S    Unknown  42.0          ORANGE  Unknown   \n288626      10665        H    Unknown  28.0           CLARK  Unknown   \n\n       APP_CHILD APP_MENBIG APP_TODDLR APP_WOMEN  ... VTR_PRI15 VTR_PRI16  \\\n84399    Unknown    Unknown    Unknown         Y  ...   Unknown   Unknown   \n484854   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n226471   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n166786   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n371588   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n...          ...        ...        ...       ...  ...       ...       ...   \n160451   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n440522   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n386269   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n258849   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n288626   Unknown    Unknown    Unknown   Unknown  ...   Unknown   Unknown   \n\n       VTR_PRI17 VTR_PRI18 VTR_PRI19 VTR_PRI20 VTR_PRI21 VTR_PRI22 WORKWOMAN  \\\n84399    Unknown   Unknown   Unknown         E   Unknown   Unknown   Unknown   \n484854   Unknown   Unknown   Unknown   Unknown   Unknown         X   Unknown   \n226471   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   \n166786   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   \n371588   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   \n...          ...       ...       ...       ...       ...       ...       ...   \n160451   Unknown         D   Unknown   Unknown   Unknown         Y   Unknown   \n440522   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   \n386269   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   \n258849   Unknown   Unknown   Unknown   Unknown   Unknown         M   Unknown   \n288626   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   Unknown   \n\n       YEARBUILT  \n84399       1986  \n484854      1955  \n226471   Unknown  \n166786   Unknown  \n371588      1870  \n...          ...  \n160451      1995  \n440522   Unknown  \n386269      2000  \n258849   Unknown  \n288626   Unknown  \n\n[500 rows x 297 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RECORD_ID</th>\n      <th>ADD_TYPE</th>\n      <th>AFAMPROFLS</th>\n      <th>AGE</th>\n      <th>AI_COUNTY_NAME</th>\n      <th>AIRCOND</th>\n      <th>APP_CHILD</th>\n      <th>APP_MENBIG</th>\n      <th>APP_TODDLR</th>\n      <th>APP_WOMEN</th>\n      <th>...</th>\n      <th>VTR_PRI15</th>\n      <th>VTR_PRI16</th>\n      <th>VTR_PRI17</th>\n      <th>VTR_PRI18</th>\n      <th>VTR_PRI19</th>\n      <th>VTR_PRI20</th>\n      <th>VTR_PRI21</th>\n      <th>VTR_PRI22</th>\n      <th>WORKWOMAN</th>\n      <th>YEARBUILT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>84399</th>\n      <td>496231</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>25.0</td>\n      <td>FLAGLER</td>\n      <td>A</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>E</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>1986</td>\n    </tr>\n    <tr>\n      <th>484854</th>\n      <td>102544</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>62.0</td>\n      <td>TALBOT</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>X</td>\n      <td>Unknown</td>\n      <td>1955</td>\n    </tr>\n    <tr>\n      <th>226471</th>\n      <td>373375</td>\n      <td>H</td>\n      <td>Unknown</td>\n      <td>55.0</td>\n      <td>SCOTT</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>166786</th>\n      <td>390809</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>61.0</td>\n      <td>SEDGWICK</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>371588</th>\n      <td>204466</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>23.0</td>\n      <td>NEWPORT</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>1870</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>160451</th>\n      <td>488765</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>39.0</td>\n      <td>HAMILTON</td>\n      <td>A</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>D</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Y</td>\n      <td>Unknown</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>440522</th>\n      <td>487245</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>51.0</td>\n      <td>PRINCE WILLIAM</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>386269</th>\n      <td>389513</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>37.0</td>\n      <td>MEIGS</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>258849</th>\n      <td>127079</td>\n      <td>S</td>\n      <td>Unknown</td>\n      <td>42.0</td>\n      <td>ORANGE</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>M</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>288626</th>\n      <td>10665</td>\n      <td>H</td>\n      <td>Unknown</td>\n      <td>28.0</td>\n      <td>CLARK</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>...</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 297 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_500.sample(n=500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T20:05:35.593513Z",
     "start_time": "2023-10-05T20:05:35.524368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with 'Y' or 'Unknown': ['AFAMPROFLS', 'APP_CHILD', 'APP_MENBIG', 'APP_TODDLR', 'APP_WOMEN', 'APP_WOMPET', 'APP_WOMPLS', 'APP_YNGMEN', 'ARTS', 'AUTOACCES', 'AUTOWORK', 'BOATING', 'BROADERLIV', 'CARDUSER', 'CATOWNER', 'CH_0002FEM', 'CH_0002MAL', 'CH_0002UNK', 'CH_0305FEM', 'CH_0305MAL', 'CH_0305UNK', 'CH_0610FEM', 'CH_0610MAL', 'CH_0610UNK', 'CH_1115FEM', 'CH_1115MAL', 'CH_1115UNK', 'CH_1617FEM', 'CH_1617MAL', 'CH_1617UNK', 'CHRISTFAM', 'COL_ANTIQ', 'COL_ARTS', 'COL_COIN', 'COL_SPORT', 'COL_STAMP', 'COMPHOMOFC', 'COMPUTERS', 'COOK_GEN', 'CURRAFFAIR', 'DEPTSTCRD', 'DIETING', 'DIYLIV', 'DOGOWNER', 'DON_ANML', 'DON_ARTCUL', 'DON_CHARIT', 'DON_CHILD', 'DON_ENVIR', 'DON_ENVWLD', 'DON_HEALTH', 'DON_INTAID', 'DON_OTHER', 'DON_POLCONS', 'DON_POLIT', 'DON_POLLIB', 'DON_RELIG', 'DON_VET', 'DONATION', 'EDU_ONLINE', 'EQUESTRIAN', 'EXER_GROUP', 'GAMING', 'GARDENER', 'GOLF', 'GRANDCHLD', 'HEALTHBEAU', 'HEATHMED', 'HH_SENIOR', 'HH_VETERAN', 'HH_YOUNGAD', 'HIGHBROW', 'HIGHENDAPP', 'HISTMIL', 'HITECHLIV', 'HOME_DECOR', 'HOMEOFFICE', 'HUNTING', 'HUNTSHOOT', 'INV_ACTIVE', 'MAIL_DONOR', 'MAILORDBUY', 'MAILORDRSP', 'MOTORCYCLE', 'NASCAR', 'PARENTING', 'PETS', 'PRESENCHLD', 'PRFL_2NDAMEND', 'PRFL_ACTIVE_MIL', 'PRFL_AMZN_PRIME', 'PRFL_ANML_RIGHTS', 'PRFL_BIDEN_SUPPORT', 'PRFL_BLM_SUPPORT', 'PRFL_BORDER_SECURITY', 'PRFL_CLINTON_SUPPORT', 'PRFL_CONSERVATIVE_NEWS', 'PRFL_EDUCATION', 'PRFL_ENVIRONMENT', 'PRFL_EVANGELICAL', 'PRFL_FENCE_SITTER', 'PRFL_GUN_CONTROL', 'PRFL_HEALTHCARE', 'PRFL_IMMIGRATION_REFORM', 'PRFL_INFLUENCER', 'PRFL_INSURANCE', 'PRFL_LABOR', 'PRFL_LIBERAL_NEWS', 'PRFL_MARIJUANA_REFORM', 'PRFL_METOO_SUPPORT', 'PRFL_MIL_SUPPORT', 'PRFL_OBAMA', 'PRFL_PERSUADABLE_VOTER', 'PRFL_SANDERS_SUPPORT', 'PRFL_TAXES', 'PRFL_TEACHERS_UNION', 'PRFL_TRUMP_SUPPORT', 'PRFL_VETERAN', 'RD_FINNEWS', 'RD_GEN', 'RD_RELIG', 'RD_SCIFI', 'RELIGINSP', 'SCISPACE', 'SCUBADIVER', 'SELFIMP', 'SINGPARENT', 'SMOKING', 'SPEC_AUTO', 'SPEC_BASE', 'SPEC_BASK', 'SPEC_FOOT', 'SPEC_HOCK', 'SPEC_SOCC', 'SPORTLEIS', 'SWEEPSTAKE', 'TELECOM', 'TENNIS', 'THEATER', 'TRAVEL', 'WORKWOMAN'] 141\n",
      "Columns with more than two categories: ['ADD_TYPE', 'AI_COUNTY_NAME', 'AIRCOND', 'ASSMLCODE', 'BUS_OWNER', 'CENSUS_ST', 'CNS_MEDINC', 'CONG_DIST', 'COUNTY_ST', 'COUNTY_TYPE', 'CRD_RANGE', 'CREDRATE', 'EDUCATION', 'ETHNIC_INFER', 'ETHNICCODE', 'ETHNICCONF', 'ETHNICGRP', 'FUND_POLIT', 'GENDER_MIX', 'GENERATION', 'HH_NUMGEN', 'HH_SIZE', 'HOMEMKTVAL', 'HOMEOWNER', 'HOMEOWNRNT', 'INCOMESTHH', 'LANGUAGE', 'LENGTH_RES', 'LIFESTAGE_CLUSTER', 'NETWORTH', 'NUMCHILD', 'OCCDETAIL', 'OCCUPATION', 'PARTY_CODE', 'PERSONS_HH', 'POOL', 'PRFL_POLITICAL_IDEOLOGY', 'PRFL_TEAPARTY', 'RELIGION', 'SEX', 'ST_LO_HOUS', 'ST_UP_HOUS', 'STATE', 'STATUS', 'TOD_PRES_DIFF_2016', 'TOD_PRES_DIFF_2016_PREC', 'TOD_PRES_DIFF_2020_PREC', 'VOTER_CNT', 'VOTER_TRLR', 'VTR_GEN00', 'VTR_GEN01', 'VTR_GEN02', 'VTR_GEN03', 'VTR_GEN04', 'VTR_GEN05', 'VTR_GEN06', 'VTR_GEN07', 'VTR_GEN08', 'VTR_GEN09', 'VTR_GEN10', 'VTR_GEN11', 'VTR_GEN12', 'VTR_GEN13', 'VTR_GEN14', 'VTR_GEN15', 'VTR_GEN16', 'VTR_GEN17', 'VTR_GEN18', 'VTR_GEN19', 'VTR_GEN20', 'VTR_GEN21', 'VTR_GEN22', 'VTR_OTH00', 'VTR_OTH01', 'VTR_OTH02', 'VTR_OTH03', 'VTR_OTH04', 'VTR_OTH05', 'VTR_OTH06', 'VTR_OTH07', 'VTR_OTH08', 'VTR_OTH09', 'VTR_OTH10', 'VTR_OTH11', 'VTR_OTH12', 'VTR_OTH13', 'VTR_OTH14', 'VTR_OTH15', 'VTR_OTH16', 'VTR_OTH17', 'VTR_OTH18', 'VTR_OTH19', 'VTR_OTH20', 'VTR_OTH21', 'VTR_OTH22', 'VTR_PPP00', 'VTR_PPP04', 'VTR_PPP08', 'VTR_PPP12', 'VTR_PPP16', 'VTR_PPP20', 'VTR_PRI00', 'VTR_PRI01', 'VTR_PRI02', 'VTR_PRI03', 'VTR_PRI04', 'VTR_PRI05', 'VTR_PRI06', 'VTR_PRI07', 'VTR_PRI08', 'VTR_PRI09', 'VTR_PRI10', 'VTR_PRI11', 'VTR_PRI12', 'VTR_PRI13', 'VTR_PRI14', 'VTR_PRI15', 'VTR_PRI16', 'VTR_PRI17', 'VTR_PRI18', 'VTR_PRI19', 'VTR_PRI20', 'VTR_PRI21', 'VTR_PRI22', 'YEARBUILT'] 125\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "#data_500 = pd.read_csv(\"/Users/nirugidla/Documents/GitHub/milestone2_MADS/data_500k.csv\", low_memory=False)\n",
    "\n",
    "# Data Cleaning - Column Names\n",
    "data_500.columns = data_500.columns.str.strip()\n",
    "\n",
    "# Data Cleaning - Drop ZIP\n",
    "data_500.drop('ZIP', axis=1, inplace=True)\n",
    "\n",
    "# Data Cleaning - Drop Duplicates\n",
    "data_500.drop_duplicates(inplace=True)\n",
    "\n",
    "# Data Cleaning - Object Columns\n",
    "for col in data_500.columns:\n",
    "    if data_500[col].dtype == 'object':\n",
    "        data_500[col] = data_500[col].str.strip()\n",
    "\n",
    "# Data Cleaning - Empty Strings\n",
    "data_500.replace('', 'Unknown', inplace=True)\n",
    "\n",
    "# Data Cleaning - NaN for Object Types\n",
    "data_500.loc[:, data_500.dtypes == 'object'] = data_500.loc[:, data_500.dtypes == 'object'].fillna('Unknown')\n",
    "\n",
    "# Data Cleaning - Drop Columns and Rows with All NaNs\n",
    "data_500.dropna(axis=1, how='all', inplace=True)\n",
    "data_500.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "# Identify numeric and non-numeric columns\n",
    "numeric_cols = data_500.select_dtypes(include=['int64', 'float64']).columns\n",
    "non_numeric_cols = data_500.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "# Data Cleaning - Removing Non-Numeric Columns with More Than 90% Missing Data\n",
    "missing_data_percentage = data_500.isnull().mean() * 100\n",
    "non_numeric_cols_to_remove = missing_data_percentage[non_numeric_cols]\n",
    "non_numeric_cols_to_remove = non_numeric_cols_to_remove[non_numeric_cols_to_remove > 90].index.tolist()\n",
    "data_500_reduced = data_500.drop(columns=non_numeric_cols_to_remove)\n",
    "\n",
    "# Update the list of non-numeric columns after removal\n",
    "non_numeric_cols = data_500_reduced.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "# Identifying Specific Types of Non-Numeric Columns\n",
    "cols_with_Y_or_Unknown = [col for col in non_numeric_cols if set(data_500_reduced[col].unique()) <= {'Y', 'Unknown'}]\n",
    "cols_with_more_than_two_categories = [col for col in non_numeric_cols if len(data_500_reduced[col].unique()) > 2]\n",
    "\n",
    "# Print identified columns\n",
    "print(\"Columns with 'Y' or 'Unknown':\", cols_with_Y_or_Unknown, len(cols_with_Y_or_Unknown))\n",
    "print(\"Columns with more than two categories:\", cols_with_more_than_two_categories, len(cols_with_more_than_two_categories))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T00:59:35.009833Z",
     "start_time": "2023-10-06T00:58:51.279752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Just the columns with Yes or Unknown non_numeric_cols "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(500000, 141)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduced_with_Y_or_Unknown = data_500[cols_with_Y_or_Unknown].copy()\n",
    "data_reduced_with_Y_or_Unknown.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T20:18:29.235627Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.63215\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming cols_with_Y_or_Unknown has been identified and data_500 has been cleaned\n",
    "data_reduced_with_Y_or_Unknown = data_500[cols_with_Y_or_Unknown].copy()\n",
    "\n",
    "# Adding the target column to this data\n",
    "data_reduced_with_Y_or_Unknown['PARTY_CODE'] = data_500['PARTY_CODE']\n",
    "\n",
    "# Remove rows where 'PARTY_CODE' is missing, as it's our target variable\n",
    "data_reduced_with_Y_or_Unknown = data_reduced_with_Y_or_Unknown[data_reduced_with_Y_or_Unknown['PARTY_CODE'].notna()]\n",
    "\n",
    "# Sample 100,000 rows from the data\n",
    "data_sample = data_reduced_with_Y_or_Unknown.sample(n=100000, random_state=42)\n",
    "\n",
    "# Count instances of each class in 'PARTY_CODE' again to filter out classes with fewer than 2 instances\n",
    "class_counts = data_sample['PARTY_CODE'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index.tolist()\n",
    "data_sample = data_sample[data_sample['PARTY_CODE'].isin(valid_classes)]\n",
    "\n",
    "# Label-encode 'PARTY_CODE' column\n",
    "le = LabelEncoder()\n",
    "data_sample['PARTY_CODE'] = le.fit_transform(data_sample['PARTY_CODE'].astype(str))\n",
    "\n",
    "# One-Hot Encoding\n",
    "data_one_hot = pd.get_dummies(data_sample, columns=cols_with_Y_or_Unknown, drop_first=True)\n",
    "\n",
    "# Splitting the Data into Training and Test Sets\n",
    "X = data_one_hot.drop('PARTY_CODE', axis=1)\n",
    "y = data_one_hot['PARTY_CODE']\n",
    "\n",
    "# Perform train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and Train XGBoost Classifier\n",
    "xgb = XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions and Evaluate the Model\n",
    "y_pred = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Model Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-05T21:09:26.275405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "   Run  Accuracy  F1_Score  Recall  \\\n0    1    0.5965  0.580370  0.5965   \n1    2    0.6105  0.595713  0.6105   \n2    3    0.6290  0.610276  0.6290   \n3    4    0.6205  0.604047  0.6205   \n4    5    0.6140  0.597579  0.6140   \n5    6    0.6205  0.604001  0.6205   \n6    7    0.6160  0.600376  0.6160   \n7    8    0.6150  0.600305  0.6150   \n8    9    0.6230  0.608591  0.6230   \n9   10    0.6220  0.603847  0.6220   \n\n                                      Top_N_Features  \n0  [PRFL_BIDEN_SUPPORT_Y, PRFL_BORDER_SECURITY_Y,...  \n1  [PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...  \n2  [PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...  \n3  [PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...  \n4  [PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...  \n5  [PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...  \n6  [PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...  \n7  [PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...  \n8  [PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...  \n9  [PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run</th>\n      <th>Accuracy</th>\n      <th>F1_Score</th>\n      <th>Recall</th>\n      <th>Top_N_Features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.5965</td>\n      <td>0.580370</td>\n      <td>0.5965</td>\n      <td>[PRFL_BIDEN_SUPPORT_Y, PRFL_BORDER_SECURITY_Y,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.6105</td>\n      <td>0.595713</td>\n      <td>0.6105</td>\n      <td>[PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.6290</td>\n      <td>0.610276</td>\n      <td>0.6290</td>\n      <td>[PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.6205</td>\n      <td>0.604047</td>\n      <td>0.6205</td>\n      <td>[PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.6140</td>\n      <td>0.597579</td>\n      <td>0.6140</td>\n      <td>[PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.6205</td>\n      <td>0.604001</td>\n      <td>0.6205</td>\n      <td>[PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.6160</td>\n      <td>0.600376</td>\n      <td>0.6160</td>\n      <td>[PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.6150</td>\n      <td>0.600305</td>\n      <td>0.6150</td>\n      <td>[PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.6230</td>\n      <td>0.608591</td>\n      <td>0.6230</td>\n      <td>[PRFL_LIBERAL_NEWS_Y, PRFL_BIDEN_SUPPORT_Y, PR...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.6220</td>\n      <td>0.603847</td>\n      <td>0.6220</td>\n      <td>[PRFL_BIDEN_SUPPORT_Y, PRFL_LIBERAL_NEWS_Y, PR...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def run_xgboost(sample_size, num_runs, top_N_features):\n",
    "    results_list = []\n",
    "\n",
    "    for run in range(1, num_runs + 1):\n",
    "        # Assuming cols_with_Y_or_Unknown has been identified and data_500 has been cleaned\n",
    "        data_reduced_with_Y_or_Unknown = data_500[cols_with_Y_or_Unknown].copy()\n",
    "\n",
    "        # Adding the target column to this data\n",
    "        data_reduced_with_Y_or_Unknown['PARTY_CODE'] = data_500['PARTY_CODE']\n",
    "\n",
    "        # Remove rows where 'PARTY_CODE' is missing, as it's our target variable\n",
    "        data_reduced_with_Y_or_Unknown = data_reduced_with_Y_or_Unknown[data_reduced_with_Y_or_Unknown['PARTY_CODE'].notna()]\n",
    "\n",
    "        # Sample data\n",
    "        data_sample = data_reduced_with_Y_or_Unknown.sample(n=sample_size, random_state=run)\n",
    "\n",
    "        # Dynamic Class Handling\n",
    "        class_counts = data_sample['PARTY_CODE'].value_counts()\n",
    "        valid_classes = class_counts[class_counts >= 2].index.tolist()\n",
    "        data_sample = data_sample[data_sample['PARTY_CODE'].isin(valid_classes)]\n",
    "\n",
    "        # Label-encode 'PARTY_CODE' column\n",
    "        le = LabelEncoder()\n",
    "        data_sample['PARTY_CODE'] = le.fit_transform(data_sample['PARTY_CODE'].astype(str))\n",
    "\n",
    "        # One-Hot Encoding\n",
    "        data_one_hot = pd.get_dummies(data_sample, columns=cols_with_Y_or_Unknown, drop_first=True)\n",
    "\n",
    "        # Splitting the Data into Training and Test Sets\n",
    "        X = data_one_hot.drop('PARTY_CODE', axis=1)\n",
    "        y = data_one_hot['PARTY_CODE']\n",
    "\n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=run, stratify=y\n",
    "        )\n",
    "\n",
    "        # Initialize and Train XGBoost Classifier\n",
    "        xgb = XGBClassifier(objective='multi:softmax', random_state=run)\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        # Make Predictions and Evaluate the Model\n",
    "        y_pred = xgb.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Get top N features\n",
    "        feature_importances = xgb.feature_importances_\n",
    "        sorted_idx = feature_importances.argsort()[::-1][:top_N_features]\n",
    "        top_features = X.columns[sorted_idx].tolist()\n",
    "\n",
    "        # Append to results list\n",
    "        results_list.append({\n",
    "            'Run': run,\n",
    "            'Accuracy': accuracy,\n",
    "            'F1_Score': f1,\n",
    "            'Recall': recall,\n",
    "            'Top_N_Features': top_features\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the results list\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Example of how to call this function\n",
    "result = run_xgboost(sample_size=10000, num_runs=10, top_N_features=10)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T21:25:59.907178Z",
     "start_time": "2023-10-05T21:25:18.650118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRFL_LIBERAL_NEWS_Y', 'PRFL_BIDEN_SUPPORT_Y', 'PRFL_BORDER_SECURITY_Y', 'PRFL_CONSERVATIVE_NEWS_Y', 'PRFL_MARIJUANA_REFORM_Y', 'PRFL_SANDERS_SUPPORT_Y', 'PRFL_2NDAMEND_Y', 'PRFL_IMMIGRATION_REFORM_Y', 'PRFL_FENCE_SITTER_Y', 'PRFL_TRUMP_SUPPORT_Y']\n",
      "+++++\n",
      "['PRFL_LIBERAL_NEWS_Y', 'PRFL_BIDEN_SUPPORT_Y', 'PRFL_BORDER_SECURITY_Y', 'PRFL_CONSERVATIVE_NEWS_Y', 'PRFL_MARIJUANA_REFORM_Y', 'PRFL_SANDERS_SUPPORT_Y', 'PRFL_2NDAMEND_Y', 'PRFL_IMMIGRATION_REFORM_Y', 'PRFL_FENCE_SITTER_Y', 'PRFL_TRUMP_SUPPORT_Y']\n",
      "+++++\n"
     ]
    }
   ],
   "source": [
    "for run in result['Top_N_Features']:\n",
    "    print(run)\n",
    "    print(\"+++++\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T21:24:36.390634Z",
     "start_time": "2023-10-05T21:24:36.388124Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Unique Features: ['PRFL_FENCE_SITTER_Y', 'GAMING_Y', 'DIYLIV_Y', 'RELIGINSP_Y', 'PRFL_BLM_SUPPORT_Y', 'HUNTING_Y', 'SPEC_HOCK_Y', 'CH_1617FEM_Y', 'HUNTSHOOT_Y']\n",
      "Most Common Features: ['PRFL_BIDEN_SUPPORT_Y', 'PRFL_BORDER_SECURITY_Y', 'PRFL_LIBERAL_NEWS_Y', 'PRFL_CONSERVATIVE_NEWS_Y', 'PRFL_MARIJUANA_REFORM_Y', 'PRFL_SANDERS_SUPPORT_Y', 'PRFL_2NDAMEND_Y', 'PRFL_IMMIGRATION_REFORM_Y', 'PRFL_TRUMP_SUPPORT_Y', 'CHRISTFAM_Y', 'CH_1617MAL_Y', 'PRFL_FENCE_SITTER_Y', 'GAMING_Y', 'DIYLIV_Y', 'RELIGINSP_Y', 'PRFL_BLM_SUPPORT_Y', 'HUNTING_Y', 'SPEC_HOCK_Y', 'CH_1617FEM_Y', 'HUNTSHOOT_Y']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming result is your DataFrame and 'Top_N_Features' is the column with the lists of top features\n",
    "all_features = [feature for sublist in result['Top_N_Features'].tolist() for feature in sublist]\n",
    "\n",
    "# Count the frequency of each feature\n",
    "feature_counts = Counter(all_features)\n",
    "\n",
    "# Find the most unique features (those that appear only once across all runs)\n",
    "most_unique_features = [feature for feature, count in feature_counts.items() if count == 1]\n",
    "\n",
    "# Find the most common features (those that appear the most across all runs)\n",
    "most_common_features = [feature for feature, count in feature_counts.most_common()]\n",
    "\n",
    "print(\"Most Unique Features:\", most_unique_features)\n",
    "print(\"Most Common Features:\", most_common_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T21:39:38.375916Z",
     "start_time": "2023-10-05T21:39:38.351908Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Just the non_numeric_cols with more than 2 values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(500000, 125)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduced_with_more_than_two_categories = data_500[cols_with_more_than_two_categories].copy()\n",
    "data_reduced_with_more_than_two_categories.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T01:00:21.458386Z",
     "start_time": "2023-10-06T01:00:21.456044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after label encoding: Index(['ADD_TYPE', 'AI_COUNTY_NAME', 'AIRCOND', 'ASSMLCODE', 'BUS_OWNER',\n",
      "       'CENSUS_ST', 'CNS_MEDINC', 'CONG_DIST', 'COUNTY_ST', 'COUNTY_TYPE',\n",
      "       ...\n",
      "       'VTR_PRI14', 'VTR_PRI15', 'VTR_PRI16', 'VTR_PRI17', 'VTR_PRI18',\n",
      "       'VTR_PRI19', 'VTR_PRI20', 'VTR_PRI21', 'VTR_PRI22', 'YEARBUILT'],\n",
      "      dtype='object', length=125)\n",
      "XGBoost Model Accuracy: 0.932\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming cols_with_Y_or_Unknown has been identified and data_500 has been cleaned\n",
    "data_reduced_with_more_than_two_categories = data_500[cols_with_more_than_two_categories].copy()\n",
    "\n",
    "# Adding the target column to this data\n",
    "data_reduced_with_more_than_two_categories['PARTY_CODE'] = data_500['PARTY_CODE']\n",
    "\n",
    "# Remove rows where 'PARTY_CODE' is missing, as it's our target variable\n",
    "data_reduced_with_more_than_two_categories = data_reduced_with_more_than_two_categories[data_reduced_with_more_than_two_categories['PARTY_CODE'].notna()]\n",
    "\n",
    "# Sample 100,000 rows from the data\n",
    "data_sample = data_reduced_with_more_than_two_categories.sample(n=100000, random_state=42)\n",
    "\n",
    "# Count instances of each class in 'PARTY_CODE' again to filter out classes with fewer than 2 instances\n",
    "class_counts = data_sample['PARTY_CODE'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index.tolist()\n",
    "data_sample = data_sample[data_sample['PARTY_CODE'].isin(valid_classes)]\n",
    "\n",
    "# Label-encode 'PARTY_CODE' column\n",
    "le = LabelEncoder()\n",
    "data_sample['PARTY_CODE'] = le.fit_transform(data_sample['PARTY_CODE'].astype(str))\n",
    "print(\"Columns after label encoding:\", data_sample.columns)\n",
    "\n",
    "\n",
    "# Identify the columns in `cols_with_more_than_two_categories` that are actually present in `data_sample`\n",
    "# Identify the columns in `cols_with_more_than_two_categories` that are actually present in `data_sample`\n",
    "cols_to_encode = [col for col in cols_with_more_than_two_categories if col in data_sample.columns and col != 'PARTY_CODE']\n",
    "\n",
    "# One-Hot Encoding\n",
    "data_one_hot = pd.get_dummies(data_sample, columns=cols_to_encode, drop_first=True)\n",
    "#print(\"Columns after one-hot encoding:\", data_one_hot.columns)\n",
    "#print(\"Columns before dropping PARTY_CODE:\", data_one_hot.columns)\n",
    "\n",
    "# Splitting the Data into Training and Test Sets\n",
    "X = data_one_hot.drop('PARTY_CODE', axis=1)\n",
    "y = data_one_hot['PARTY_CODE']\n",
    "\n",
    "# Perform train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Sanitize column names to remove characters not allowed by XGBoost\n",
    "X_train.columns = X_train.columns.str.replace('[', '_').str.replace(']', '_').str.replace('<', '_')\n",
    "X_test.columns = X_test.columns.str.replace('[', '_').str.replace(']', '_').str.replace('<', '_')\n",
    "\n",
    "# Initialize and Train XGBoost Classifier\n",
    "xgb = XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions and Evaluate the Model\n",
    "y_pred = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Model Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T00:16:09.467769Z",
     "start_time": "2023-10-06T00:07:19.135615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1...\n",
      "Starting run 2...\n",
      "Elapsed time: 321.73 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "def timer_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer_decorator\n",
    "def run_xgboost(data, cols_with_more_than_two_categories, sample_size=100000, num_runs=1, top_N_features=10):\n",
    "    results_list = []\n",
    "\n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Starting run {run}...\")\n",
    "        # Replicate the original code inside the loop\n",
    "        data_reduced_with_more_than_two_categories = data[cols_with_more_than_two_categories].copy()\n",
    "        data_reduced_with_more_than_two_categories['PARTY_CODE'] = data['PARTY_CODE']\n",
    "        data_reduced_with_more_than_two_categories = data_reduced_with_more_than_two_categories[data_reduced_with_more_than_two_categories['PARTY_CODE'].notna()]\n",
    "        data_sample = data_reduced_with_more_than_two_categories.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        class_counts = data_sample['PARTY_CODE'].value_counts()\n",
    "        valid_classes = class_counts[class_counts >= 2].index.tolist()\n",
    "        data_sample = data_sample[data_sample['PARTY_CODE'].isin(valid_classes)]\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        data_sample['PARTY_CODE'] = le.fit_transform(data_sample['PARTY_CODE'].astype(str))\n",
    "        \n",
    "        cols_to_encode = [col for col in cols_with_more_than_two_categories if col in data_sample.columns and col != 'PARTY_CODE']\n",
    "        data_one_hot = pd.get_dummies(data_sample, columns=cols_to_encode, drop_first=True)\n",
    "        \n",
    "        X = data_one_hot.drop('PARTY_CODE', axis=1)\n",
    "        y = data_one_hot['PARTY_CODE']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        X_train.columns = X_train.columns.str.replace('[', '_').str.replace(']', '_').str.replace('<', '_')\n",
    "        X_test.columns = X_test.columns.str.replace('[', '_').str.replace(']', '_').str.replace('<', '_')\n",
    "        \n",
    "        xgb = XGBClassifier(objective='multi:softmax', random_state=42)\n",
    "        xgb.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = xgb.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        feature_importances = xgb.feature_importances_\n",
    "        sorted_idx = feature_importances.argsort()[::-1][:top_N_features]\n",
    "        top_features = X.columns[sorted_idx].tolist()\n",
    "\n",
    "        results_list.append({\n",
    "            'Run': run,\n",
    "            'Accuracy': accuracy,\n",
    "            'F1_Score': f1,\n",
    "            'Recall': recall,\n",
    "            'Top_N_Features': top_features\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Assuming data_500 and cols_with_more_than_two_categories are already defined\n",
    "result = run_xgboost(data_500, cols_with_more_than_two_categories, sample_size=50000, num_runs=2, top_N_features=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T21:14:16.909593Z",
     "start_time": "2023-10-07T21:08:55.177600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   Run  Accuracy  F1_Score   Recall  \\\n0    1   0.93566  0.928801  0.93566   \n1    2   0.93566  0.928801  0.93566   \n\n                                      Top_N_Features  \n0  [CENSUS_ST_48, PRFL_POLITICAL_IDEOLOGY_L, CENS...  \n1  [CENSUS_ST_48, PRFL_POLITICAL_IDEOLOGY_L, CENS...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Run</th>\n      <th>Accuracy</th>\n      <th>F1_Score</th>\n      <th>Recall</th>\n      <th>Top_N_Features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.93566</td>\n      <td>0.928801</td>\n      <td>0.93566</td>\n      <td>[CENSUS_ST_48, PRFL_POLITICAL_IDEOLOGY_L, CENS...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.93566</td>\n      <td>0.928801</td>\n      <td>0.93566</td>\n      <td>[CENSUS_ST_48, PRFL_POLITICAL_IDEOLOGY_L, CENS...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result['Top_N_Features'][0]\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:15:51.405376Z",
     "start_time": "2023-10-07T17:15:51.400283Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Unique Features: []\n",
      "Most Common Features: ['CENSUS_ST_48', 'PRFL_POLITICAL_IDEOLOGY_L', 'CENSUS_ST_13', 'PRFL_POLITICAL_IDEOLOGY_Unknown', 'TOD_PRES_DIFF_2020_PREC_Unknown']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming result is your DataFrame and 'Top_N_Features' is the column with the lists of top features\n",
    "all_features = [feature for sublist in result['Top_N_Features'].tolist() for feature in sublist]\n",
    "\n",
    "# Count the frequency of each feature\n",
    "feature_counts = Counter(all_features)\n",
    "\n",
    "# Find the most unique features (those that appear only once across all runs)\n",
    "most_unique_features = [feature for feature, count in feature_counts.items() if count == 1]\n",
    "\n",
    "# Find the most common features (those that appear the most across all runs)\n",
    "most_common_features = [feature for feature, count in feature_counts.most_common()]\n",
    "\n",
    "print(\"Most Unique Features:\", most_unique_features)\n",
    "print(\"Most Common Features:\", most_common_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:16:37.965906Z",
     "start_time": "2023-10-07T17:16:37.959075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
