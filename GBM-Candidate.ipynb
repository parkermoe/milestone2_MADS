{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18dd35c2-c402-4e3f-ba6e-471d0989046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c69fd4-4403-4c3a-9458-719b36661a99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca848a4d-8d47-4fcf-a2e7-30a99f5461df",
   "metadata": {},
   "source": [
    "## Predicting who is planning on voting Republican vs Democrat... \n",
    "### with all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c91bdba-d127-49db-85a1-3b9c693fd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset again\n",
    "data = pd.read_csv('data/surveydata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e901566c-f777-4025-a52b-3bc41fcfd46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7724358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66       114\n",
      "           1       0.79      0.87      0.83       198\n",
      "\n",
      "    accuracy                           0.77       312\n",
      "   macro avg       0.76      0.74      0.74       312\n",
      "weighted avg       0.77      0.77      0.77       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Filter out potential data leakage columns\n",
    "filtered_data = data.drop(columns=['Q2_Support', 'Q3_Party', 'Q4_LikelyVoter', 'Q5_TrumpSupport', 'SURVEY_TYPE', 'RECORD_ID'], errors='ignore')\n",
    "\n",
    "# Create the binary target variable\n",
    "filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x in ['President Joe Biden','Marianne Williamson','Robert F. Kennedy Jr.'] else 1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X = filtered_data.drop(columns=['target', 'Q1_Candidate'])  # Features (excluding 'target' and 'Q1_Candidate')\n",
    "y = filtered_data['target']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify and convert categorical columns to string type:\n",
    "# This line uses a list comprehension to identify columns in the X_train dataset where the data type is object, which typically \n",
    "# means the column contains string or categorical data. The resulting list of column names is stored in categorical_cols.\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# These lines ensure that all values in the identified categorical columns are of string type. \n",
    "# This is done to ensure consistency when applying transformations like encoding.\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Preprocessing:\n",
    "# These preprocessing steps ensure that the data is clean, consistent, and in the right format for the Gradient Boosting Machine (GBM) or any other machine learning model.\n",
    "\n",
    "# Here, we define a Pipeline for preprocessing categorical data:\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    \n",
    "# The 'imputer' step uses the SimpleImputer to fill any missing values in the categorical columns. The strategy 'most_frequent' \n",
    "# fills missing values with the most frequent value in the column.\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    \n",
    "# The 'encoder' step applies OneHotEncoder to convert categorical values into a format suitable for modeling. It creates binary columns \n",
    "# for each category and indicates the presence of the category with a 1 or 0. The handle_unknown='ignore' parameter ensures that if the \n",
    "# model encounters an unknown category in the test set (i.e., a category not seen during training), it will ignore it.\n",
    "    \n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define the numerical transformer:\n",
    "#This step uses the SimpleImputer to fill any missing values in the numerical columns. The strategy 'mean' fills missing values with the mean of the column.\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Combining the Transformers:\n",
    "# The ColumnTransformer allows different columns or column subsets of the input data to be transformed separately. Here, we apply the \n",
    "# numerical_transformer to the numerical columns and the categorical_transformer to the categorical columns. This way, we can preprocess \n",
    "# numerical and categorical data differently within the same transformer.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, X_train.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Applying the Preprocessor:\n",
    "# The fit_transform method is used on the training set to learn any parameters (like mean values for imputation or categories for one-hot encoding)\n",
    "# and apply the transformations. The transform method is then used on the test set to apply the same transformations using the parameters learned from the training set.\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# GBM Classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gbm_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = gbm_classifier.predict(X_test_preprocessed)\n",
    "accuracy_after_filtering = accuracy_score(y_test, y_pred)\n",
    "classification_rep_after_filtering = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy_after_filtering)\n",
    "print(classification_rep_after_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbcd61e6-5b5f-4f0d-9bfb-1c423abd9609",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>PRFL_IMMIGRATION_REFORM_</td>\n",
       "      <td>0.130365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>PRFL_IMMIGRATION_REFORM_Y</td>\n",
       "      <td>0.054376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRFL_CHOICELIFE</td>\n",
       "      <td>0.050129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>PRFL_POLITICAL_IDEOLOGY_C</td>\n",
       "      <td>0.049499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>PRFL_LIBERAL_NEWS_nan</td>\n",
       "      <td>0.028351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>PRFL_CONSERVATIVE_NEWS_nan</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>VTR_PPP20_</td>\n",
       "      <td>0.027759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VP_GEN</td>\n",
       "      <td>0.023986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>PARTY_CODE_R</td>\n",
       "      <td>0.023372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENSUS_TRK</td>\n",
       "      <td>0.021980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>VTR_PPP20_M</td>\n",
       "      <td>0.021022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TOD_PRES_O_2016_PREC</td>\n",
       "      <td>0.019784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PARTY_MIX</td>\n",
       "      <td>0.019299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNSUS_PCTW</td>\n",
       "      <td>0.016471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.014161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>VTR_PPP16_R</td>\n",
       "      <td>0.014041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>0.012309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>VTR_PRI22_</td>\n",
       "      <td>0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>AI_COUNTY_NAME_MARION</td>\n",
       "      <td>0.010788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>VTR_GEN18_</td>\n",
       "      <td>0.010239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Importance\n",
       "1691   PRFL_IMMIGRATION_REFORM_     0.130365\n",
       "1692   PRFL_IMMIGRATION_REFORM_Y    0.054376\n",
       "13               PRFL_CHOICELIFE    0.050129\n",
       "1711   PRFL_POLITICAL_IDEOLOGY_C    0.049499\n",
       "1700       PRFL_LIBERAL_NEWS_nan    0.028351\n",
       "1678  PRFL_CONSERVATIVE_NEWS_nan    0.027855\n",
       "2931                 VTR_PPP20_     0.027759\n",
       "29                        VP_GEN    0.023986\n",
       "1641                PARTY_CODE_R    0.023372\n",
       "2                     CENSUS_TRK    0.021980\n",
       "2935                 VTR_PPP20_M    0.021022\n",
       "22          TOD_PRES_O_2016_PREC    0.019784\n",
       "12                     PARTY_MIX    0.019299\n",
       "10                    CNSUS_PCTW    0.016471\n",
       "0                            AGE    0.014161\n",
       "2927                 VTR_PPP16_R    0.014041\n",
       "33                           ZIP    0.012309\n",
       "3092                 VTR_PRI22_     0.011023\n",
       "313        AI_COUNTY_NAME_MARION    0.010788\n",
       "2774                 VTR_GEN18_     0.010239"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the GBM model\n",
    "feature_importances = gbm_classifier.feature_importances_\n",
    "\n",
    "# Get the one-hot encoded feature names from the preprocessor\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the original numerical column names with the one-hot encoded feature names\n",
    "all_feature_names = list(X_train.select_dtypes(exclude=['object']).columns) + list(ohe_feature_names)\n",
    "\n",
    "# Create a DataFrame to map feature names to their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance and get the top 20 features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad94c45-8e01-4fa8-8a12-fe60be21c0f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### with selected features (columns that begin with \"PRF\", \"DON\", \"VTR\", and \"TOD\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76befec6-1a13-44b4-bcee-a5f766b70366",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_7852\\2874126431.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x in ['President Joe Biden','Marianne Williamson','Robert F. Kennedy Jr.'] else 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7724358974358975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65       114\n",
      "           1       0.78      0.89      0.83       198\n",
      "\n",
      "    accuracy                           0.77       312\n",
      "   macro avg       0.76      0.73      0.74       312\n",
      "weighted avg       0.77      0.77      0.76       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select columns based on the specified prefixes\n",
    "selected_columns = [col for col in data.columns if col.startswith((\"PRF\", \"DON\", \"VTR\", \"TOD\",'Q1_'))]\n",
    "\n",
    "# Extract the selected columns along with the 'target' column\n",
    "filtered_data = data[selected_columns]\n",
    "\n",
    "# Create the binary target variable\n",
    "filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x in ['President Joe Biden','Marianne Williamson','Robert F. Kennedy Jr.'] else 1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X = filtered_data.drop(columns=['target', 'Q1_Candidate'])  # Features (excluding 'target' and 'Q1_Candidate')\n",
    "y = filtered_data['target']                                # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify and convert categorical columns to string type\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, X_train.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# GBM Classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gbm_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = gbm_classifier.predict(X_test_preprocessed)\n",
    "accuracy_after_filtering = accuracy_score(y_test, y_pred)\n",
    "classification_rep_after_filtering = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy_after_filtering)\n",
    "print(classification_rep_after_filtering)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4489386-8099-48c9-bcb8-c7455c656d13",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>PRFL_IMMIGRATION_REFORM_Y</td>\n",
       "      <td>0.119809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>PRFL_IMMIGRATION_REFORM_</td>\n",
       "      <td>0.085944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>PRFL_POLITICAL_IDEOLOGY_C</td>\n",
       "      <td>0.065242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRFL_CHOICELIFE</td>\n",
       "      <td>0.052726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>VTR_PPP20_</td>\n",
       "      <td>0.032160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>PRFL_LIBERAL_NEWS_nan</td>\n",
       "      <td>0.031418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOD_PRES_O_2016_PREC</td>\n",
       "      <td>0.030075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>VTR_PPP20_M</td>\n",
       "      <td>0.024635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>VTR_GEN22_</td>\n",
       "      <td>0.021873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>VTR_PRI22_</td>\n",
       "      <td>0.021587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>PRFL_CONSERVATIVE_NEWS_Y</td>\n",
       "      <td>0.019637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PRFL_CONSERVATIVE_NEWS_nan</td>\n",
       "      <td>0.017992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOD_PRES_D_2020_PREC</td>\n",
       "      <td>0.014798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TOD_PRES_O_2020_PREC</td>\n",
       "      <td>0.011087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>PRFL_BIDEN_SUPPORT_nan</td>\n",
       "      <td>0.010434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOD_PRES_R_2016</td>\n",
       "      <td>0.010248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>PRFL_BIDEN_SUPPORT_Y</td>\n",
       "      <td>0.010121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>VTR_GEN20_A</td>\n",
       "      <td>0.009779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOD_PRES_D_2016</td>\n",
       "      <td>0.009592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>VTR_OTH13_</td>\n",
       "      <td>0.009422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature  Importance\n",
       "75    PRFL_IMMIGRATION_REFORM_Y    0.119809\n",
       "74    PRFL_IMMIGRATION_REFORM_     0.085944\n",
       "94    PRFL_POLITICAL_IDEOLOGY_C    0.065242\n",
       "0               PRFL_CHOICELIFE    0.052726\n",
       "826                 VTR_PPP20_     0.032160\n",
       "83        PRFL_LIBERAL_NEWS_nan    0.031418\n",
       "9          TOD_PRES_O_2016_PREC    0.030075\n",
       "830                 VTR_PPP20_M    0.024635\n",
       "690                 VTR_GEN22_     0.021873\n",
       "987                 VTR_PRI22_     0.021587\n",
       "60     PRFL_CONSERVATIVE_NEWS_Y    0.019637\n",
       "61   PRFL_CONSERVATIVE_NEWS_nan    0.017992\n",
       "7          TOD_PRES_D_2020_PREC    0.014798\n",
       "10         TOD_PRES_O_2020_PREC    0.011087\n",
       "53       PRFL_BIDEN_SUPPORT_nan    0.010434\n",
       "11              TOD_PRES_R_2016    0.010248\n",
       "52         PRFL_BIDEN_SUPPORT_Y    0.010121\n",
       "678                 VTR_GEN20_A    0.009779\n",
       "5               TOD_PRES_D_2016    0.009592\n",
       "747                 VTR_OTH13_     0.009422"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the GBM model\n",
    "feature_importances = gbm_classifier.feature_importances_\n",
    "\n",
    "# Get the one-hot encoded feature names from the preprocessor\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the original numerical column names with the one-hot encoded feature names\n",
    "all_feature_names = list(X_train.select_dtypes(exclude=['object']).columns) + list(ohe_feature_names)\n",
    "\n",
    "# Create a DataFrame to map feature names to their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance and get the top 20 features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090a59f-13c3-4790-87c3-8b17abd8f45c",
   "metadata": {},
   "source": [
    "### with only voter data (columns that begin with \"VTR\", and \"TOD\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8cefda6-36c9-4fac-abcc-ca0a717b5306",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_7852\\1686127329.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x in ['President Joe Biden','Marianne Williamson','Robert F. Kennedy Jr.'] else 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.43      0.54       114\n",
      "           1       0.73      0.90      0.81       198\n",
      "\n",
      "    accuracy                           0.73       312\n",
      "   macro avg       0.73      0.67      0.67       312\n",
      "weighted avg       0.73      0.73      0.71       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select columns based on the specified prefixes\n",
    "selected_columns = [col for col in data.columns if col.startswith((\"VTR\", \"TOD\",'Q1_'))]\n",
    "\n",
    "# Extract the selected columns along with the 'target' column\n",
    "filtered_data = data[selected_columns]\n",
    "\n",
    "# Create the binary target variable\n",
    "filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x in ['President Joe Biden','Marianne Williamson','Robert F. Kennedy Jr.'] else 1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X = filtered_data.drop(columns=['target', 'Q1_Candidate'])  # Features (excluding 'target' and 'Q1_Candidate')\n",
    "y = filtered_data['target']                                # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify and convert categorical columns to string type\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, X_train.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# GBM Classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gbm_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = gbm_classifier.predict(X_test_preprocessed)\n",
    "accuracy_after_filtering = accuracy_score(y_test, y_pred)\n",
    "classification_rep_after_filtering = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy_after_filtering)\n",
    "print(classification_rep_after_filtering)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9e51b13-5805-46fe-9c33-056f96f0f680",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>VTR_PPP20_M</td>\n",
       "      <td>0.067716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOD_PRES_R_2016_PREC</td>\n",
       "      <td>0.059066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOD_PRES_D_2020_PREC</td>\n",
       "      <td>0.047259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>VTR_PPP16_R</td>\n",
       "      <td>0.040123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>VTR_PRI22_R</td>\n",
       "      <td>0.034350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOD_PRES_D_2016_PREC</td>\n",
       "      <td>0.034179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>VTR_PPP20_D</td>\n",
       "      <td>0.034080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>VTR_GEN20_A</td>\n",
       "      <td>0.032336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>VTR_PPP20_Z</td>\n",
       "      <td>0.029489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOD_PRES_R_2016</td>\n",
       "      <td>0.027735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>VTR_PPP20_</td>\n",
       "      <td>0.026989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>VTR_PRI18_D</td>\n",
       "      <td>0.020813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>VTR_PRI22_D</td>\n",
       "      <td>0.018623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOD_PRES_O_2020_PREC</td>\n",
       "      <td>0.016357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOD_PRES_O_2016_PREC</td>\n",
       "      <td>0.015753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOD_PRES_R_2020_PREC</td>\n",
       "      <td>0.014483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOD_PRES_D_2016</td>\n",
       "      <td>0.012948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>VTR_PRI18_R</td>\n",
       "      <td>0.012468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>TOD_PRES_DIFF_2016_PREC_09R</td>\n",
       "      <td>0.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>VTR_PRI02_Y</td>\n",
       "      <td>0.010386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Importance\n",
       "728                  VTR_PPP20_M    0.067716\n",
       "7           TOD_PRES_R_2016_PREC    0.059066\n",
       "2           TOD_PRES_D_2020_PREC    0.047259\n",
       "720                  VTR_PPP16_R    0.040123\n",
       "891                  VTR_PRI22_R    0.034350\n",
       "1           TOD_PRES_D_2016_PREC    0.034179\n",
       "726                  VTR_PPP20_D    0.034080\n",
       "576                  VTR_GEN20_A    0.032336\n",
       "733                  VTR_PPP20_Z    0.029489\n",
       "6                TOD_PRES_R_2016    0.027735\n",
       "724                  VTR_PPP20_     0.026989\n",
       "854                  VTR_PRI18_D    0.020813\n",
       "887                  VTR_PRI22_D    0.018623\n",
       "5           TOD_PRES_O_2020_PREC    0.016357\n",
       "4           TOD_PRES_O_2016_PREC    0.015753\n",
       "8           TOD_PRES_R_2020_PREC    0.014483\n",
       "0                TOD_PRES_D_2016    0.012948\n",
       "858                  VTR_PRI18_R    0.012468\n",
       "166  TOD_PRES_DIFF_2016_PREC_09R    0.012346\n",
       "751                  VTR_PRI02_Y    0.010386"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the GBM model\n",
    "feature_importances = gbm_classifier.feature_importances_\n",
    "\n",
    "# Get the one-hot encoded feature names from the preprocessor\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the original numerical column names with the one-hot encoded feature names\n",
    "all_feature_names = list(X_train.select_dtypes(exclude=['object']).columns) + list(ohe_feature_names)\n",
    "\n",
    "# Create a DataFrame to map feature names to their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance and get the top 20 features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce44440-7a17-43b9-8369-80d1d63a2f52",
   "metadata": {},
   "source": [
    "## Predicting which Republican supporters support Trump vs Other Republican... \n",
    "### with all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36cb41c0-2985-4035-9e75-acd71a558af5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56       103\n",
      "           1       0.54      0.57      0.55        97\n",
      "\n",
      "    accuracy                           0.56       200\n",
      "   macro avg       0.56      0.56      0.55       200\n",
      "weighted avg       0.56      0.56      0.56       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out respondents who said they would vote for ‘President Joe Biden’, ‘Robert F. Kennedy Jr.’, or ‘Marianne Williamson’\n",
    "filtered_data = data[~data['Q1_Candidate'].isin(['President Joe Biden', 'Robert F. Kennedy Jr.', 'Marianne Williamson'])]\n",
    "\n",
    "# Filter out potential data leakage columns\n",
    "filtered_data = filtered_data.drop(columns=['Q2_Support', 'Q3_Party', 'Q4_LikelyVoter', 'Q5_TrumpSupport', 'SURVEY_TYPE', 'RECORD_ID'], errors='ignore')\n",
    "\n",
    "# Create the binary target variable\n",
    "filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x == 'President Donald Trump' else 1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X = filtered_data.drop(columns=['target', 'Q1_Candidate'])  # Features (excluding 'target' and 'Q1_Candidate')\n",
    "y = filtered_data['target']                                # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify and convert categorical columns to string type\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, X_train.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# GBM Classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gbm_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = gbm_classifier.predict(X_test_preprocessed)\n",
    "accuracy_after_filtering = accuracy_score(y_test, y_pred)\n",
    "classification_rep_after_filtering = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy_after_filtering) \n",
    "print(classification_rep_after_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7648f797-50b6-45a0-903e-8bf35ca1da2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENSUS_TRK</td>\n",
       "      <td>0.039683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TOD_PRES_O_2020_PREC</td>\n",
       "      <td>0.036358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TOD_PRES_O_2016_PREC</td>\n",
       "      <td>0.030787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>HH_SIZE_6</td>\n",
       "      <td>0.026457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TOD_PRES_R_2016_PREC</td>\n",
       "      <td>0.025009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>PRFL_LIBERAL_NEWS_Y</td>\n",
       "      <td>0.024191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>COUNTY_ST</td>\n",
       "      <td>0.023232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>VTR_OTH13_</td>\n",
       "      <td>0.021771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNSUS_PCTM</td>\n",
       "      <td>0.020247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>VTR_PRI13_</td>\n",
       "      <td>0.017542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>PRFL_CONSERVATIVE_NEWS_Y</td>\n",
       "      <td>0.017224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PARTY_MIX</td>\n",
       "      <td>0.015308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>VOTER_CNT_11</td>\n",
       "      <td>0.014174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>CONG_DIST_01</td>\n",
       "      <td>0.013607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>EDUCATION_A</td>\n",
       "      <td>0.013126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VP_GEN</td>\n",
       "      <td>0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>INCOMESTHH_M</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>TOD_PRES_DIFF_2020_PREC_12R</td>\n",
       "      <td>0.011873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRAIL_CNT</td>\n",
       "      <td>0.010540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>LENGTH_RES_14</td>\n",
       "      <td>0.009990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature  Importance\n",
       "2                      CENSUS_TRK    0.039683\n",
       "23           TOD_PRES_O_2020_PREC    0.036358\n",
       "22           TOD_PRES_O_2016_PREC    0.030787\n",
       "1124                    HH_SIZE_6    0.026457\n",
       "25           TOD_PRES_R_2016_PREC    0.025009\n",
       "1407          PRFL_LIBERAL_NEWS_Y    0.024191\n",
       "11                      COUNTY_ST    0.023232\n",
       "2476                  VTR_OTH13_     0.021771\n",
       "7                      CNSUS_PCTM    0.020247\n",
       "2626                  VTR_PRI13_     0.017542\n",
       "1386     PRFL_CONSERVATIVE_NEWS_Y    0.017224\n",
       "12                      PARTY_MIX    0.015308\n",
       "2246                 VOTER_CNT_11    0.014174\n",
       "888                  CONG_DIST_01    0.013607\n",
       "1009                  EDUCATION_A    0.013126\n",
       "29                         VP_GEN    0.012683\n",
       "1187                 INCOMESTHH_M    0.012329\n",
       "2108  TOD_PRES_DIFF_2020_PREC_12R    0.011873\n",
       "27                      TRAIL_CNT    0.010540\n",
       "1224                LENGTH_RES_14    0.009990"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the GBM model\n",
    "feature_importances = gbm_classifier.feature_importances_\n",
    "\n",
    "# Get the one-hot encoded feature names from the preprocessor\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the original numerical column names with the one-hot encoded feature names\n",
    "all_feature_names = list(X_train.select_dtypes(exclude=['object']).columns) + list(ohe_feature_names)\n",
    "\n",
    "# Create a DataFrame to map feature names to their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance and get the top 20 features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a547bd-569c-4b2e-a56f-5469cfd1dad7",
   "metadata": {},
   "source": [
    "### with selected features (columns that begin with \"PRF\", \"DON\", \"VTR\", and \"TOD\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd5a0e09-468e-40bf-bc12-a3fa4ebfa6d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_7852\\3703427189.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x == 'President Donald Trump' else 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Trump vs other Repub candidates with \"PRF\", \"DON\", \"VTR\", and \"TOD\" columns\n",
      "0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       103\n",
      "           1       0.57      0.63      0.60        97\n",
      "\n",
      "    accuracy                           0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset again\n",
    "data = pd.read_csv('data/surveydata.csv')\n",
    "\n",
    "# Select columns based on the specified prefixes\n",
    "selected_columns = [col for col in data.columns if col.startswith((\"PRF\", \"DON\", \"VTR\", \"TOD\",'Q1_'))]\n",
    "\n",
    "# Extract the selected columns along with the 'target' column\n",
    "data = data[selected_columns]\n",
    "data\n",
    "\n",
    "# Filter out respondents who said they would vote for ‘President Joe Biden’, ‘Robert F. Kennedy Jr.’, or ‘Marianne Williamson’\n",
    "filtered_data = data[~data['Q1_Candidate'].isin(['President Joe Biden', 'Robert F. Kennedy Jr.', 'Marianne Williamson'])]\n",
    "\n",
    "# Create the binary target variable\n",
    "filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x == 'President Donald Trump' else 1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X = filtered_data.drop(columns=['target', 'Q1_Candidate'])  # Features (excluding 'target' and 'Q1_Candidate')\n",
    "y = filtered_data['target']                                # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Convert all categorical columns to string type\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Create transformers\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, X_train.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Preprocess training and testing data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Initialize and train the GBM classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gbm_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gbm_classifier.predict(X_test_preprocessed)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_all_columns = accuracy_score(y_test, y_pred)\n",
    "classification_rep_all_columns = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"Predicting Trump vs other Repub candidates with \"PRF\", \"DON\", \"VTR\", and \"TOD\" columns\"\"\")\n",
    "print(accuracy_all_columns) \n",
    "print(classification_rep_all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9202d19c-d996-413f-b0df-71a72724d730",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOD_PRES_O_2016_PREC</td>\n",
       "      <td>0.073974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TOD_PRES_O_2020_PREC</td>\n",
       "      <td>0.065441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TOD_PRES_R_2016_PREC</td>\n",
       "      <td>0.040869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOD_PRES_R_2016</td>\n",
       "      <td>0.036261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>VTR_OTH13_</td>\n",
       "      <td>0.030118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>VTR_PRI13_</td>\n",
       "      <td>0.027019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>PRFL_LIBERAL_NEWS_Y</td>\n",
       "      <td>0.024982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>TOD_PRES_DIFF_2020_PREC_12R</td>\n",
       "      <td>0.018054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOD_PRES_D_2016_PREC</td>\n",
       "      <td>0.017720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>PRFL_CONSERVATIVE_NEWS_Y</td>\n",
       "      <td>0.016548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>PRFL_POLITICAL_IDEOLOGY_C</td>\n",
       "      <td>0.015825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>VTR_GEN06_</td>\n",
       "      <td>0.015574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PRFL_CONSERVATIVE_NEWS_nan</td>\n",
       "      <td>0.015238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>VTR_PRI22_</td>\n",
       "      <td>0.014419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>VTR_GEN18_E</td>\n",
       "      <td>0.013389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>VTR_PRI01_Y</td>\n",
       "      <td>0.013371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOD_PRES_D_2020_PREC</td>\n",
       "      <td>0.012955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>TOD_PRES_DIFF_2016_PREC_11D</td>\n",
       "      <td>0.012251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>PRFL_LIBERAL_NEWS_nan</td>\n",
       "      <td>0.011959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>TOD_PRES_DIFF_2016_17D</td>\n",
       "      <td>0.011743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Importance\n",
       "9           TOD_PRES_O_2016_PREC    0.073974\n",
       "10          TOD_PRES_O_2020_PREC    0.065441\n",
       "12          TOD_PRES_R_2016_PREC    0.040869\n",
       "11               TOD_PRES_R_2016    0.036261\n",
       "700                  VTR_OTH13_     0.030118\n",
       "850                  VTR_PRI13_     0.027019\n",
       "81           PRFL_LIBERAL_NEWS_Y    0.024982\n",
       "427  TOD_PRES_DIFF_2020_PREC_12R    0.018054\n",
       "6           TOD_PRES_D_2016_PREC    0.017720\n",
       "60      PRFL_CONSERVATIVE_NEWS_Y    0.016548\n",
       "93     PRFL_POLITICAL_IDEOLOGY_C    0.015825\n",
       "577                  VTR_GEN06_     0.015574\n",
       "61    PRFL_CONSERVATIVE_NEWS_nan    0.015238\n",
       "912                  VTR_PRI22_     0.014419\n",
       "627                  VTR_GEN18_E    0.013389\n",
       "787                  VTR_PRI01_Y    0.013371\n",
       "7           TOD_PRES_D_2020_PREC    0.012955\n",
       "264  TOD_PRES_DIFF_2016_PREC_11D    0.012251\n",
       "82         PRFL_LIBERAL_NEWS_nan    0.011959\n",
       "143       TOD_PRES_DIFF_2016_17D    0.011743"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the GBM model\n",
    "feature_importances = gbm_classifier.feature_importances_\n",
    "\n",
    "# Get the one-hot encoded feature names from the preprocessor\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the original numerical column names with the one-hot encoded feature names\n",
    "all_feature_names = list(X_train.select_dtypes(exclude=['object']).columns) + list(ohe_feature_names)\n",
    "\n",
    "# Create a DataFrame to map feature names to their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance and get the top 20 features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d04398-16e9-41f6-b10e-b7b31b123999",
   "metadata": {},
   "source": [
    "### with only voter data (columns that begin with \"VTR\", and \"TOD\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4a24f80-dcae-44bb-8a88-c8ef00c10f71",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59       103\n",
      "           1       0.57      0.60      0.59        97\n",
      "\n",
      "    accuracy                           0.59       200\n",
      "   macro avg       0.59      0.59      0.59       200\n",
      "weighted avg       0.59      0.59      0.59       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns based on the specified prefixes\n",
    "selected_columns = [col for col in data.columns if col.startswith((\"VTR\", \"TOD\",'Q1_'))]\n",
    "\n",
    "# Extract the selected columns along with the 'target' column\n",
    "filtered_data = data[selected_columns]\n",
    "\n",
    "# Filter out respondents who said they would vote for ‘President Joe Biden’, ‘Robert F. Kennedy Jr.’, or ‘Marianne Williamson’\n",
    "filtered_data = filtered_data[~filtered_data['Q1_Candidate'].isin(['President Joe Biden', 'Robert F. Kennedy Jr.', 'Marianne Williamson'])]\n",
    "\n",
    "# Create the binary target variable\n",
    "filtered_data['target'] = filtered_data['Q1_Candidate'].apply(lambda x: 0 if x == 'President Donald Trump' else 1)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X = filtered_data.drop(columns=['target', 'Q1_Candidate'])  # Features (excluding 'target' and 'Q1_Candidate')\n",
    "y = filtered_data['target']                                # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify and convert categorical columns to string type\n",
    "categorical_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype(str)\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype(str)\n",
    "\n",
    "# Preprocessing\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, X_train.select_dtypes(exclude=['object']).columns),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# GBM Classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gbm_classifier.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = gbm_classifier.predict(X_test_preprocessed)\n",
    "accuracy_after_filtering = accuracy_score(y_test, y_pred)\n",
    "classification_rep_after_filtering = classification_report(y_test, y_pred)\n",
    "\n",
    "print(accuracy_after_filtering)\n",
    "print(classification_rep_after_filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45df93a8-0cb4-4ce3-b320-efef80304cc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOD_PRES_O_2016_PREC</td>\n",
       "      <td>0.074298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOD_PRES_O_2020_PREC</td>\n",
       "      <td>0.054610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOD_PRES_R_2016</td>\n",
       "      <td>0.053594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOD_PRES_R_2016_PREC</td>\n",
       "      <td>0.047318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>VTR_OTH13_</td>\n",
       "      <td>0.035806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOD_PRES_D_2016_PREC</td>\n",
       "      <td>0.033817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOD_PRES_O_2016</td>\n",
       "      <td>0.024384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>VTR_PRI13_</td>\n",
       "      <td>0.023137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOD_PRES_R_2020_PREC</td>\n",
       "      <td>0.022452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>VTR_GEN18_E</td>\n",
       "      <td>0.019196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>VTR_PPP20_R</td>\n",
       "      <td>0.016482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOD_PRES_D_2016</td>\n",
       "      <td>0.016381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TOD_PRES_DIFF_2016_17D</td>\n",
       "      <td>0.015315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>VTR_PPP20_D</td>\n",
       "      <td>0.013964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TOD_PRES_DIFF_2016_58R</td>\n",
       "      <td>0.013547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>TOD_PRES_DIFF_2016_PREC_11D</td>\n",
       "      <td>0.013516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>TOD_PRES_DIFF_2020_PREC_12R</td>\n",
       "      <td>0.013495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>TOD_PRES_DIFF_2020_PREC_22R</td>\n",
       "      <td>0.012795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>TOD_PRES_DIFF_2016_PREC_07D</td>\n",
       "      <td>0.012602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>TOD_PRES_DIFF_2020_PREC_49R</td>\n",
       "      <td>0.011263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Importance\n",
       "4           TOD_PRES_O_2016_PREC    0.074298\n",
       "5           TOD_PRES_O_2020_PREC    0.054610\n",
       "6                TOD_PRES_R_2016    0.053594\n",
       "7           TOD_PRES_R_2016_PREC    0.047318\n",
       "600                  VTR_OTH13_     0.035806\n",
       "1           TOD_PRES_D_2016_PREC    0.033817\n",
       "3                TOD_PRES_O_2016    0.024384\n",
       "750                  VTR_PRI13_     0.023137\n",
       "8           TOD_PRES_R_2020_PREC    0.022452\n",
       "527                  VTR_GEN18_E    0.019196\n",
       "676                  VTR_PPP20_R    0.016482\n",
       "0                TOD_PRES_D_2016    0.016381\n",
       "43        TOD_PRES_DIFF_2016_17D    0.015315\n",
       "672                  VTR_PPP20_D    0.013964\n",
       "118       TOD_PRES_DIFF_2016_58R    0.013547\n",
       "164  TOD_PRES_DIFF_2016_PREC_11D    0.013516\n",
       "327  TOD_PRES_DIFF_2020_PREC_12R    0.013495\n",
       "347  TOD_PRES_DIFF_2020_PREC_22R    0.012795\n",
       "156  TOD_PRES_DIFF_2016_PREC_07D    0.012602\n",
       "398  TOD_PRES_DIFF_2020_PREC_49R    0.011263"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the GBM model\n",
    "feature_importances = gbm_classifier.feature_importances_\n",
    "\n",
    "# Get the one-hot encoded feature names from the preprocessor\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Combine the original numerical column names with the one-hot encoded feature names\n",
    "all_feature_names = list(X_train.select_dtypes(exclude=['object']).columns) + list(ohe_feature_names)\n",
    "\n",
    "# Create a DataFrame to map feature names to their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance and get the top 20 features\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf463c3-b505-4b1d-965d-ef23edc94097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c7e77-5c15-47c6-b7d0-b1e1f67e97dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badee42e-48bd-4557-9289-6be847ee9f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c5c30-d072-4b73-9350-0ee49c32b6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d3b5f-fda6-4905-be87-70177f591b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41b1a4-d4ee-4f92-ba2a-a2e47a720f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666b12b-aaca-4602-a363-3759256bdea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dec92-1629-43a2-a2b6-e97d9f18d959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d00ff-6f00-4bc3-9766-5cb2fd0f5b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f0339-c92c-4508-8c5c-52e7abcf2b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94aff2-6973-401b-aea7-1b422ac5c44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850e484-bf5b-484d-861c-5e4438082926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b69e8-4533-4080-9f77-8aec9ca08e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d176107-97e2-4498-8785-372e312b6701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fef30-e2bc-4a3e-87c8-5632c84b26d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c2b4f-d40d-4dd9-97d7-6aab7cb567f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
